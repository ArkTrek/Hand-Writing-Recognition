{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iRB7jPNzkSwh"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# load data\n",
        "def load_data(path):\n",
        "    images = []\n",
        "    labels = []\n",
        "    for i in range(10):\n",
        "        for img in ImageDataGenerator(rescale=1./255).flow_from_directory(f'{path}/{i}', target_size=(32, 32), classes=[i]):\n",
        "            images.append(img[0])\n",
        "            labels.append(img[1])\n",
        "    return np.array(images), np.array(labels)\n",
        "\n",
        "# prepare data\n",
        "def prepare_data(images, labels):\n",
        "    images = images.astype('float32')\n",
        "    labels = to_categorical(labels)\n",
        "    return images, labels\n",
        "\n",
        "# load data\n",
        "images, labels = load_data('path/to/handwriting/dataset')\n",
        "\n",
        "# prepare data\n",
        "images, labels = prepare_data(images, labels)\n",
        "\n",
        "# split data into training and testing sets\n",
        "images_train, images_test, labels_train, labels_test = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# convert labels to categorical\n",
        "labels_train = to_categorical(np.argmax(labels_train, axis=1))\n",
        "labels_test = to_categorical(np.argmax(labels_test, axis=1))\n",
        "\n",
        "# normalize images\n",
        "images_train = images_train / 255\n",
        "images_test = images_test / 255\n",
        "\n",
        "# build the model\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(32, 32, 3)))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "# compile the model\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# train the model\n",
        "model.fit(images_train, labels_train, batch_size=128, epochs=10, validation_data=(images_test, labels_test))\n",
        "\n",
        "# evaluate the model\n",
        "score = model.evaluate(images_test, labels_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ]
    }
  ]
}